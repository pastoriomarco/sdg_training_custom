rt-detr (TAO)
=============

This folder contains a TAO RT-DETR training spec wired for SDG outputs generated by:
`src/sdg_training_custom/custom_sdg/generate_sdg_splits.sh`

The workflow below starts at container pull/login and runs end-to-end training.

Prerequisites
-------------
You should complete the following sequence before starting TAO training in this README.

Host requirements:
- Ubuntu host with NVIDIA driver + Docker + NVIDIA Container Toolkit.
- NGC API key (for `nvcr.io` access).
- GPU visible from host: `nvidia-smi` works.
- GPU visible from Docker: `docker run --rm --gpus all nvidia/cuda:13.0.1-base-ubuntu22.04 nvidia-smi`.

Data preparation sequence (must be done first):
1. Generate SDG data with this repository (COCO outputs under `${SDG_OUT}`).
2. Run the generic SDG split generator:
   `src/sdg_training_custom/custom_sdg/generate_sdg_splits.sh`.
3. Verify expected SDG outputs exist:
   - `${SDG_OUT}/train/Replicator`, `${SDG_OUT}/val/Replicator`, `${SDG_OUT}/test/Replicator`
   - one `coco_*.json` file in each split directory
   - `${SDG_OUT}/classes_unique.txt`
4. Run `prepare_tao_coco.py` in this folder (step 2 below) to create TAO-ready files.
5. Update `num_classes` in the RT-DETR spec (step 3 below).

If step 1 is not done yet, follow the SDG generation guidance in:
- `src/sdg_training_custom/README.md`
- `src/sdg_training_custom/custom_sdg/generate_sdg_splits.sh`

Recommended paths used below
----------------------------
```bash
export SDG_WS=/home/tndlux/workspaces/sdg
export SDG_OUT=/home/tndlux/synthetic_out
```

1) Login and pull TAO container
-------------------------------
```bash
docker login nvcr.io
# Username: $oauthtoken
# Password: <your NGC API key>

docker pull nvcr.io/nvidia/tao/tao-toolkit:6.25.11-pyt
```

If this image fails due driver/CUDA mismatch, use:
```bash
docker pull nvcr.io/nvidia/tao/tao-toolkit:6.25.10-pyt
```

Container tag selection rule:
- Start with `nvcr.io/nvidia/tao/tao-toolkit:6.25.11-pyt`.
- If container startup/training fails with host stack compatibility issues, switch to `6.25.10-pyt`.
- Use the same chosen tag consistently for train/evaluate/export commands.

2) Prepare TAO-friendly COCO files and class map
------------------------------------------------
The SDG script writes COCO JSON files with random suffixes (e.g. `coco_annotations_abcd1234.json`).
Also, category IDs may be sparse (for example only `201`) while TAO expects contiguous IDs.
Run the prep script once per dataset refresh:

```bash
python3 "${SDG_WS}/src/sdg_training_custom/rt-detr/prepare_tao_coco.py" \
  --out-root "${SDG_OUT}"
```

This writes:
- `${SDG_OUT}/train/coco_annotations.json`
- `${SDG_OUT}/val/coco_annotations.json`
- `${SDG_OUT}/test/coco_annotations.json`
- `${SDG_OUT}/classmap.txt`

3) Set `num_classes` in the training spec
-----------------------------------------
```bash
NUM_CLASSES=$(wc -l < "${SDG_OUT}/classmap.txt")
sed -i "s/^  num_classes: .*/  num_classes: ${NUM_CLASSES}/" \
  "${SDG_WS}/src/sdg_training_custom/rt-detr/rtdetr_train.yaml"
```

4) Run RT-DETR training in Docker
---------------------------------
```bash
docker run --rm -it --gpus all \
  --shm-size=16g --ulimit memlock=-1 --ulimit stack=67108864 \
  -v "${SDG_WS}:/workspace" \
  -v "${SDG_OUT}:/data/synthetic_out" \
  nvcr.io/nvidia/tao/tao-toolkit:6.25.11-pyt \
  rtdetr train \
  -e /workspace/src/sdg_training_custom/rt-detr/rtdetr_train.yaml \
  results_dir=/workspace/src/sdg_training_custom/rt-detr/results
```

Notes:
- `results_dir` is where checkpoints/logs will be written on the host.
- Current default spec in this folder is tuned for your 8 GB RTX 4070 and validated with TAO dry-run:
  `backbone=resnet_50`, `batch_size=6`, `workers=8`, `fp16`, `activation_checkpoint=true`.
  In local testing, `batch_size=8` was unstable (SIGSEGV), while `batch_size=6` was stable.
- If `model_latest.pth` is not present, replace it with your latest checkpoint file in `/workspace/src/sdg_training_custom/rt-detr/results/train/`.

Optional quick overrides
------------------------
If you want to sweep without editing YAML, append overrides to the command:

```bash
# More conservative (if you hit instability)
dataset.batch_size=4 model.backbone=resnet_34

# Maximum tested stable in this setup
dataset.batch_size=6 model.backbone=resnet_50
```

5) Evaluate
-----------
```bash
docker run --rm -it --gpus all \
  --shm-size=16g --ulimit memlock=-1 --ulimit stack=67108864 \
  -v "${SDG_WS}:/workspace" \
  -v "${SDG_OUT}:/data/synthetic_out" \
  nvcr.io/nvidia/tao/tao-toolkit:6.25.11-pyt \
  rtdetr evaluate \
  -e /workspace/src/sdg_training_custom/rt-detr/rtdetr_train.yaml \
  results_dir=/workspace/src/sdg_training_custom/rt-detr/results \
  evaluate.checkpoint=/workspace/src/sdg_training_custom/rt-detr/results/train/model_latest.pth
```

6) Export ONNX
--------------
If `model_latest.pth` exists, you can export directly:

```bash
docker run --rm -it --gpus all \
  --shm-size=16g --ulimit memlock=-1 --ulimit stack=67108864 \
  -v "${SDG_WS}:/workspace" \
  -v "${SDG_OUT}:/data/synthetic_out" \
  nvcr.io/nvidia/tao/tao-toolkit:6.25.11-pyt \
  rtdetr export \
  -e /workspace/src/sdg_training_custom/rt-detr/rtdetr_train.yaml \
  results_dir=/workspace/src/sdg_training_custom/rt-detr/results \
  export.checkpoint=/workspace/src/sdg_training_custom/rt-detr/results/train/model_latest.pth \
  export.onnx_file=/workspace/src/sdg_training_custom/rt-detr/results/export/model.onnx
```

If `model_latest.pth` is missing, export from the latest epoch checkpoint:

```bash
LATEST_EPOCH_CKPT=$(basename "$(ls -1 \
  "${SDG_WS}/src/sdg_training_custom/rt-detr/results/train/model_epoch_"*.pth | sort | tail -n1)")

docker run --rm -it --gpus all \
  --shm-size=16g --ulimit memlock=-1 --ulimit stack=67108864 \
  -v "${SDG_WS}:/workspace" \
  -v "${SDG_OUT}:/data/synthetic_out" \
  nvcr.io/nvidia/tao/tao-toolkit:6.25.11-pyt \
  rtdetr export \
  -e /workspace/src/sdg_training_custom/rt-detr/rtdetr_train.yaml \
  results_dir=/workspace/src/sdg_training_custom/rt-detr/results \
  export.checkpoint=/workspace/src/sdg_training_custom/rt-detr/results/train/${LATEST_EPOCH_CKPT} \
  export.onnx_file=/workspace/src/sdg_training_custom/rt-detr/results/export/model.onnx
```

7) Next step for Isaac ROS
--------------------------
After ONNX export, build a TensorRT engine and configure Isaac ROS RT-DETR / FoundationPose with:
- engine path
- model input tensor names and output tensor names expected by RT-DETR decoder
- class count / labels matching your training data

References
----------
- TAO RT-DETR training: https://docs.nvidia.com/tao/tao-toolkit/latest/text/cv_finetuning/pytorch/object_detection/rt_detr.html
- TAO containers and mapping: https://docs.nvidia.com/tao/tao-toolkit/latest/text/quick_start_guide/running_from_containers.html
- TAO release notes (container tags): https://docs.nvidia.com/tao/tao-toolkit/latest/text/release_notes.html
